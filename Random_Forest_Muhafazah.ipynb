{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random Forest Muhafazah",
      "provenance": [],
      "authorship_tag": "ABX9TyNwyXH/kZSsuMOIl95bVpyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhafazah94/UASRANDOMFORESTCLASSIFICATION/blob/main/Random_Forest_Muhafazah.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRexnKF-GcbI"
      },
      "source": [
        "import pandas as pd #Python Data Analysis Library \n",
        "import numpy as np #Python Scientific Library (Umumnya membantu \n",
        "#dalam urusan list)\n",
        " \n",
        "#Selective import modul-modul Scikit Learn \n",
        "#(Scikit Learn memiliki banyak modul machine learning)\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2otCvpFwG6PW",
        "outputId": "37b25524-a3d8-4552-dcc8-04153535afe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "new_names = ['sepal_length','sepal_width','petal_length','petal_width','iris_class']\n",
        "dataset = pd.read_csv(url, names=new_names, skiprows=0, delimiter=',')\n",
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  150 non-null    float64\n",
            " 1   sepal_width   150 non-null    float64\n",
            " 2   petal_length  150 non-null    float64\n",
            " 3   petal_width   150 non-null    float64\n",
            " 4   iris_class    150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vLqRtGnG_2x",
        "outputId": "efd80299-9c72-4909-a037-dff6fd69f373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "dataset.head(6)\n",
        " #change head with sample and tail."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>iris_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width   iris_class\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
              "5           5.4          3.9           1.7          0.4  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szbhwozUHO3O",
        "outputId": "13f36c9f-f328-430f-937e-1ec81fce8fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "dataset.groupby('iris_class').count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iris_class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Iris-setosa</th>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Iris-virginica</th>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 sepal_length  sepal_width  petal_length  petal_width\n",
              "iris_class                                                           \n",
              "Iris-setosa                50           50            50           50\n",
              "Iris-versicolor            50           50            50           50\n",
              "Iris-virginica             50           50            50           50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u00Wims8Hbp2",
        "outputId": "24897d03-ff5b-4fa7-c8c9-6805d384b949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y = dataset['iris_class']\n",
        "x = dataset.drop(['iris_class'], axis=1)\n",
        "\n",
        "print (\"dataset : \",dataset.shape)\n",
        "print (\"x : \",x.shape)\n",
        "print (\"y : \",y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset :  (150, 5)\n",
            "x :  (150, 4)\n",
            "y :  (150,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR1W90MGHxYK",
        "outputId": "66461aab-0b1e-4cae-f1e1-bb958809f581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "#one hot encoding\n",
        "y=pd.get_dummies(y)\n",
        "y.sample(7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iris-setosa</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
              "17             1                0               0\n",
              "131            0                0               1\n",
              "18             1                0               0\n",
              "143            0                0               1\n",
              "107            0                0               1\n",
              "140            0                0               1\n",
              "92             0                1               0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvghCGcCIAau",
        "outputId": "a72d60d6-a477-4b0c-c1fa-0552dd6ea9ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Generate Training and Validation Sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3) #0.3 data sebagai data test\n",
        "\n",
        "#converting to float 32bit\n",
        "x_train = np.array(x_train).astype(np.float32)\n",
        "x_test  = np.array(x_test).astype(np.float32)\n",
        "y_train = np.array(y_train).astype(np.float32)\n",
        "y_test  = np.array(y_test).astype(np.float32)\n",
        "\n",
        "#print data split for validation\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(105, 4) (105, 3)\n",
            "(45, 4) (45, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjw00TNjIMx1",
        "outputId": "1dc5b4c8-6853-46f6-c80d-638246fffdbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=4)\n",
        "pca.fit(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=4, random_state=None,\n",
              "    svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0lNmCc8IYgz",
        "outputId": "984ff658-a0ea-4741-f96d-89b350390dab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(pca.explained_variance_ratio_)\n",
        "print(pca.singular_values_)\n",
        "print(pca.components_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.92461621 0.05301557 0.01718514 0.00518309]\n",
            "[25.08986398  6.00785254  3.42053538  1.87850234]\n",
            "[[ 0.36158968 -0.08226889  0.85657211  0.35884393]\n",
            " [ 0.65653988  0.72971237 -0.1757674  -0.07470647]\n",
            " [-0.58099728  0.59641809  0.07252408  0.54906091]\n",
            " [ 0.31725455 -0.32409435 -0.47971899  0.75112056]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZd-YJ45IcQ8",
        "outputId": "e1bf238a-5dc4-4dc0-a7e7-098eab743fc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# K-Nearest Neighbours\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "Model = KNeighborsClassifier(n_neighbors=7) #Inisialisasi model Machine Learning yang digunakan.\n",
        "Model.fit(x_train, y_train) #Proses training hanya 1 baris ini saja.\n",
        "y_pred = Model.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))  # Mencetak Summary \n",
        "print(confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))) # Mencetak Conf Matrix\n",
        "print('accuracy is',accuracy_score(y_pred,y_test)) # Mencetak Accuracy score\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        17\n",
            "           1       0.83      1.00      0.91        15\n",
            "           2       1.00      0.77      0.87        13\n",
            "\n",
            "   micro avg       0.93      0.93      0.93        45\n",
            "   macro avg       0.94      0.92      0.93        45\n",
            "weighted avg       0.94      0.93      0.93        45\n",
            " samples avg       0.93      0.93      0.93        45\n",
            "\n",
            "[[17  0  0]\n",
            " [ 0 15  0]\n",
            " [ 0  3 10]]\n",
            "accuracy is 0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5AMyckKIn8q",
        "outputId": "a6816553-f04b-441f-8564-7c9e612825cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "Model = MLPClassifier(hidden_layer_sizes=(10,5),  \n",
        "                      max_iter=200, \n",
        "                      alpha=0.01, \n",
        "                      solver='sgd', verbose=1,  \n",
        "                      random_state=121) \n",
        "h=Model.fit(x_train,y_train)\n",
        "y_pred=Model.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred)) # Mencetak Summary \n",
        "\n",
        "print(confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))) # Mencetak Confusion Matrix \n",
        "\n",
        "print('accuracy is ',accuracy_score(y_pred,y_test)) #Accuracy Score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2.55470845\n",
            "Iteration 2, loss = 2.51253403\n",
            "Iteration 3, loss = 2.45817295\n",
            "Iteration 4, loss = 2.39557008\n",
            "Iteration 5, loss = 2.33171477\n",
            "Iteration 6, loss = 2.26922699\n",
            "Iteration 7, loss = 2.20972129\n",
            "Iteration 8, loss = 2.15441144\n",
            "Iteration 9, loss = 2.10420130\n",
            "Iteration 10, loss = 2.05993156\n",
            "Iteration 11, loss = 2.02153417\n",
            "Iteration 12, loss = 1.98915905\n",
            "Iteration 13, loss = 1.96273156\n",
            "Iteration 14, loss = 1.94143117\n",
            "Iteration 15, loss = 1.92463557\n",
            "Iteration 16, loss = 1.91235606\n",
            "Iteration 17, loss = 1.90371090\n",
            "Iteration 18, loss = 1.89785512\n",
            "Iteration 19, loss = 1.89334433\n",
            "Iteration 20, loss = 1.89022097\n",
            "Iteration 21, loss = 1.88769634\n",
            "Iteration 22, loss = 1.88511827\n",
            "Iteration 23, loss = 1.88222436\n",
            "Iteration 24, loss = 1.87907434\n",
            "Iteration 25, loss = 1.87555862\n",
            "Iteration 26, loss = 1.87164569\n",
            "Iteration 27, loss = 1.86741965\n",
            "Iteration 28, loss = 1.86297005\n",
            "Iteration 29, loss = 1.85835948\n",
            "Iteration 30, loss = 1.85363949\n",
            "Iteration 31, loss = 1.84890289\n",
            "Iteration 32, loss = 1.84406314\n",
            "Iteration 33, loss = 1.83917406\n",
            "Iteration 34, loss = 1.83433099\n",
            "Iteration 35, loss = 1.82954059\n",
            "Iteration 36, loss = 1.82482927\n",
            "Iteration 37, loss = 1.82021053\n",
            "Iteration 38, loss = 1.81569948\n",
            "Iteration 39, loss = 1.81130927\n",
            "Iteration 40, loss = 1.80706767\n",
            "Iteration 41, loss = 1.80298294\n",
            "Iteration 42, loss = 1.79910399\n",
            "Iteration 43, loss = 1.79542076\n",
            "Iteration 44, loss = 1.79211841\n",
            "Iteration 45, loss = 1.78902954\n",
            "Iteration 46, loss = 1.78604130\n",
            "Iteration 47, loss = 1.78316147\n",
            "Iteration 48, loss = 1.78035587\n",
            "Iteration 49, loss = 1.77760141\n",
            "Iteration 50, loss = 1.77489261\n",
            "Iteration 51, loss = 1.77224755\n",
            "Iteration 52, loss = 1.76966446\n",
            "Iteration 53, loss = 1.76711830\n",
            "Iteration 54, loss = 1.76460335\n",
            "Iteration 55, loss = 1.76211655\n",
            "Iteration 56, loss = 1.75964678\n",
            "Iteration 57, loss = 1.75720664\n",
            "Iteration 58, loss = 1.75477528\n",
            "Iteration 59, loss = 1.75236105\n",
            "Iteration 60, loss = 1.74995611\n",
            "Iteration 61, loss = 1.74756607\n",
            "Iteration 62, loss = 1.74518614\n",
            "Iteration 63, loss = 1.74281646\n",
            "Iteration 64, loss = 1.74049711\n",
            "Iteration 65, loss = 1.73819008\n",
            "Iteration 66, loss = 1.73588861\n",
            "Iteration 67, loss = 1.73360249\n",
            "Iteration 68, loss = 1.73133708\n",
            "Iteration 69, loss = 1.72906959\n",
            "Iteration 70, loss = 1.72680268\n",
            "Iteration 71, loss = 1.72453324\n",
            "Iteration 72, loss = 1.72225656\n",
            "Iteration 73, loss = 1.71998497\n",
            "Iteration 74, loss = 1.71769739\n",
            "Iteration 75, loss = 1.71539347\n",
            "Iteration 76, loss = 1.71307360\n",
            "Iteration 77, loss = 1.71074289\n",
            "Iteration 78, loss = 1.70840437\n",
            "Iteration 79, loss = 1.70605278\n",
            "Iteration 80, loss = 1.70369016\n",
            "Iteration 81, loss = 1.70131351\n",
            "Iteration 82, loss = 1.69892130\n",
            "Iteration 83, loss = 1.69651726\n",
            "Iteration 84, loss = 1.69409600\n",
            "Iteration 85, loss = 1.69165555\n",
            "Iteration 86, loss = 1.68920636\n",
            "Iteration 87, loss = 1.68674424\n",
            "Iteration 88, loss = 1.68426641\n",
            "Iteration 89, loss = 1.68176865\n",
            "Iteration 90, loss = 1.67925725\n",
            "Iteration 91, loss = 1.67673597\n",
            "Iteration 92, loss = 1.67419441\n",
            "Iteration 93, loss = 1.67164430\n",
            "Iteration 94, loss = 1.66909109\n",
            "Iteration 95, loss = 1.66650418\n",
            "Iteration 96, loss = 1.66391270\n",
            "Iteration 97, loss = 1.66129813\n",
            "Iteration 98, loss = 1.65866017\n",
            "Iteration 99, loss = 1.65600361\n",
            "Iteration 100, loss = 1.65332392\n",
            "Iteration 101, loss = 1.65062102\n",
            "Iteration 102, loss = 1.64789472\n",
            "Iteration 103, loss = 1.64515105\n",
            "Iteration 104, loss = 1.64238427\n",
            "Iteration 105, loss = 1.63959310\n",
            "Iteration 106, loss = 1.63677618\n",
            "Iteration 107, loss = 1.63393436\n",
            "Iteration 108, loss = 1.63106971\n",
            "Iteration 109, loss = 1.62818047\n",
            "Iteration 110, loss = 1.62526591\n",
            "Iteration 111, loss = 1.62232633\n",
            "Iteration 112, loss = 1.61936785\n",
            "Iteration 113, loss = 1.61638118\n",
            "Iteration 114, loss = 1.61336673\n",
            "Iteration 115, loss = 1.61032562\n",
            "Iteration 116, loss = 1.60725653\n",
            "Iteration 117, loss = 1.60416162\n",
            "Iteration 118, loss = 1.60103853\n",
            "Iteration 119, loss = 1.59788747\n",
            "Iteration 120, loss = 1.59470850\n",
            "Iteration 121, loss = 1.59150166\n",
            "Iteration 122, loss = 1.58826755\n",
            "Iteration 123, loss = 1.58500439\n",
            "Iteration 124, loss = 1.58171282\n",
            "Iteration 125, loss = 1.57839387\n",
            "Iteration 126, loss = 1.57504458\n",
            "Iteration 127, loss = 1.57166724\n",
            "Iteration 128, loss = 1.56826060\n",
            "Iteration 129, loss = 1.56482463\n",
            "Iteration 130, loss = 1.56135921\n",
            "Iteration 131, loss = 1.55786456\n",
            "Iteration 132, loss = 1.55434287\n",
            "Iteration 133, loss = 1.55079583\n",
            "Iteration 134, loss = 1.54721910\n",
            "Iteration 135, loss = 1.54361330\n",
            "Iteration 136, loss = 1.53997761\n",
            "Iteration 137, loss = 1.53631258\n",
            "Iteration 138, loss = 1.53261843\n",
            "Iteration 139, loss = 1.52889551\n",
            "Iteration 140, loss = 1.52516880\n",
            "Iteration 141, loss = 1.52142035\n",
            "Iteration 142, loss = 1.51764587\n",
            "Iteration 143, loss = 1.51383519\n",
            "Iteration 144, loss = 1.51000345\n",
            "Iteration 145, loss = 1.50615517\n",
            "Iteration 146, loss = 1.50228782\n",
            "Iteration 147, loss = 1.49839772\n",
            "Iteration 148, loss = 1.49448512\n",
            "Iteration 149, loss = 1.49055350\n",
            "Iteration 150, loss = 1.48660272\n",
            "Iteration 151, loss = 1.48263508\n",
            "Iteration 152, loss = 1.47866426\n",
            "Iteration 153, loss = 1.47467167\n",
            "Iteration 154, loss = 1.47068568\n",
            "Iteration 155, loss = 1.46667455\n",
            "Iteration 156, loss = 1.46264636\n",
            "Iteration 157, loss = 1.45861852\n",
            "Iteration 158, loss = 1.45458188\n",
            "Iteration 159, loss = 1.45053776\n",
            "Iteration 160, loss = 1.44649409\n",
            "Iteration 161, loss = 1.44245977\n",
            "Iteration 162, loss = 1.43841705\n",
            "Iteration 163, loss = 1.43436413\n",
            "Iteration 164, loss = 1.43031427\n",
            "Iteration 165, loss = 1.42624902\n",
            "Iteration 166, loss = 1.42216885\n",
            "Iteration 167, loss = 1.41809713\n",
            "Iteration 168, loss = 1.41404327\n",
            "Iteration 169, loss = 1.40998799\n",
            "Iteration 170, loss = 1.40594677\n",
            "Iteration 171, loss = 1.40190354\n",
            "Iteration 172, loss = 1.39785635\n",
            "Iteration 173, loss = 1.39380606\n",
            "Iteration 174, loss = 1.38975628\n",
            "Iteration 175, loss = 1.38569899\n",
            "Iteration 176, loss = 1.38164449\n",
            "Iteration 177, loss = 1.37759152\n",
            "Iteration 178, loss = 1.37353912\n",
            "Iteration 179, loss = 1.36948342\n",
            "Iteration 180, loss = 1.36543526\n",
            "Iteration 181, loss = 1.36139246\n",
            "Iteration 182, loss = 1.35734435\n",
            "Iteration 183, loss = 1.35329677\n",
            "Iteration 184, loss = 1.34924895\n",
            "Iteration 185, loss = 1.34520175\n",
            "Iteration 186, loss = 1.34115638\n",
            "Iteration 187, loss = 1.33711206\n",
            "Iteration 188, loss = 1.33307013\n",
            "Iteration 189, loss = 1.32903103\n",
            "Iteration 190, loss = 1.32499537\n",
            "Iteration 191, loss = 1.32096375\n",
            "Iteration 192, loss = 1.31693671\n",
            "Iteration 193, loss = 1.31291479\n",
            "Iteration 194, loss = 1.30889849\n",
            "Iteration 195, loss = 1.30488870\n",
            "Iteration 196, loss = 1.30088520\n",
            "Iteration 197, loss = 1.29688895\n",
            "Iteration 198, loss = 1.29290025\n",
            "Iteration 199, loss = 1.28892020\n",
            "Iteration 200, loss = 1.28494806\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        17\n",
            "           1       0.00      0.00      0.00        15\n",
            "           2       1.00      0.38      0.56        13\n",
            "\n",
            "   micro avg       1.00      0.49      0.66        45\n",
            "   macro avg       0.67      0.46      0.52        45\n",
            "weighted avg       0.67      0.49      0.54        45\n",
            " samples avg       0.49      0.49      0.49        45\n",
            "\n",
            "[[17  0  0]\n",
            " [15  0  0]\n",
            " [ 8  0  5]]\n",
            "accuracy is  0.4888888888888889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZpMK0MRIwSz",
        "outputId": "8714dd5b-1d68-4174-ca4e-4b9401ee9162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(h.loss_curve_)\n",
        "plt.title('Loss History')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbf1560acc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}